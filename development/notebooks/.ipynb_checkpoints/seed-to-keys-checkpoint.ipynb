{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Tezos Keys from Mnemonic\n",
    "\n",
    "The following shows how to go from a 24 word mnemonic phrase to entropy then back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mnemonic import Mnemonic\n",
    "import hashlib as hl\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise fossil turtle truth slide garment current debris oven monkey december swear lawn derive wheat develop chief offer music abuse cram since plug retire\n"
     ]
    }
   ],
   "source": [
    "mnemo = Mnemonic(\"english\")\n",
    "phrase = mnemo.generate(256)\n",
    "print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b\"\\x95\\xcb\\x7f\\xab\\xf4\\xec\\xb8\\xbf\\xcd\\x81\\xc3\\x9d\\xd1\\xe4\\xe2\\xed\\xc7\\xe0v\\xfey\\xe4\\'\\xd3.G\\x80\\x93#\\x92i\\xb5\")\n",
      "[149, 203, 127, 171, 244, 236, 184, 191, 205, 129, 195, 157, 209, 228, 226, 237, 199, 224, 118, 254, 121, 228, 39, 211, 46, 71, 128, 147, 35, 146, 105, 181]\n",
      "95cb7fabf4ecb8bfcd81c39dd1e4e2edc7e076fe79e427d32e478093239269b5\n"
     ]
    }
   ],
   "source": [
    "entropy = mnemo.to_entropy(phrase)\n",
    "entropy_list = list(entropy)\n",
    "print(entropy)\n",
    "print(entropy_list)\n",
    "print(entropy.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# calculate checksum length\n",
    "el = len(entropy)*8 # length in bits\n",
    "csl = int(el/32) # checksum length\n",
    "print(csl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95cb7fabf4ecb8bfcd81c39dd1e4e2edc7e076fe79e427d32e478093239269b5bf\n"
     ]
    }
   ],
   "source": [
    "h = hl.sha256()\n",
    "h.update(entropy)\n",
    "entropy.append(h.digest()[0])\n",
    "print(entropy.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1]\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "# convert byte array to bit array\n",
    "bits = []\n",
    "for byte in entropy:\n",
    "    for i in range(8):\n",
    "        if (byte & 0b10000000 >> i):\n",
    "            bits.append(1)\n",
    "        else:\n",
    "            bits.append(0)\n",
    "        \n",
    "print(bits)\n",
    "print(len(bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vocab\n",
    "# import the vocabulary\n",
    "f = open('bip39english.txt', 'r')\n",
    "vocab = [line.strip('\\n') for line in f]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "noise fossil turtle truth slide garment current debris oven monkey december swear lawn derive wheat develop chief offer music abuse cram since plug retire\n"
     ]
    }
   ],
   "source": [
    "# iterate through bits with 11 bit chunks\n",
    "my_words = []\n",
    "for k in range(0,int(len(bits)/11)):\n",
    "    chunk = bits[k*11:k*11+11]\n",
    "    index = 0\n",
    "    for j in range(11):\n",
    "        index += chunk[j]*2**(11-1-j)\n",
    "    my_words.append(vocab[index])\n",
    "my_phrase = ' '.join(my_words)\n",
    "print(my_phrase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entropy to Mnemonic\n",
    "\n",
    "The following shows how to go from a random seed (entropy) to 24-word mnemonic phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aba66986f3cf0c4c8364921dbb0feddaa8b4a542c96daf48bcc50f367dcb14c9\n"
     ]
    }
   ],
   "source": [
    "# generate 256 bit random number\n",
    "myentropy = bytearray(np.random.bytes(32))\n",
    "print(myentropy.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aba66986f3cf0c4c8364921dbb0feddaa8b4a542c96daf48bcc50f367dcb14c980\n"
     ]
    }
   ],
   "source": [
    "# add hash byte\n",
    "h = hl.sha256()\n",
    "h.update(myentropy)\n",
    "myentropy.append(h.digest()[0])\n",
    "print(myentropy.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
      "264\n"
     ]
    }
   ],
   "source": [
    "# convert byte array to bit array\n",
    "bits = []\n",
    "for byte in myentropy:\n",
    "    for i in range(8):\n",
    "        if (byte & 0b10000000 >> i):\n",
    "            bits.append(1)\n",
    "        else:\n",
    "            bits.append(0)\n",
    "        \n",
    "print(bits)\n",
    "print(len(bits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import vocab\n",
    "# import the vocabulary\n",
    "f = open('bip39english.txt', 'r')\n",
    "vocab = [line.strip('\\n') for line in f]\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "produce crew giant travel valid chaos assault myself buffalo such window relief mercy famous arctic color quantum echo course bunker guitar tortoise farm copy\n"
     ]
    }
   ],
   "source": [
    "# iterate through bits with 11 bit chunks\n",
    "my_words = []\n",
    "for k in range(0,int(len(bits)/11)):\n",
    "    chunk = bits[k*11:k*11+11]\n",
    "    index = 0\n",
    "    for j in range(11):\n",
    "        index += chunk[j]*2**(11-1-j)\n",
    "    my_words.append(vocab[index])\n",
    "my_phrase = ' '.join(my_words)\n",
    "print(my_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bytearray(b'\\xab\\xa6i\\x86\\xf3\\xcf\\x0cL\\x83d\\x92\\x1d\\xbb\\x0f\\xed\\xda\\xa8\\xb4\\xa5B\\xc9m\\xafH\\xbc\\xc5\\x0f6}\\xcb\\x14\\xc9')\n",
      "[171, 166, 105, 134, 243, 207, 12, 76, 131, 100, 146, 29, 187, 15, 237, 218, 168, 180, 165, 66, 201, 109, 175, 72, 188, 197, 15, 54, 125, 203, 20, 201]\n",
      "aba66986f3cf0c4c8364921dbb0feddaa8b4a542c96daf48bcc50f367dcb14c9\n"
     ]
    }
   ],
   "source": [
    "# check\n",
    "e = mnemo.to_entropy(my_phrase)\n",
    "e_list = list(e)\n",
    "print(e)\n",
    "print(e_list)\n",
    "print(e.hex())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnemonic to Seed\n",
    "\n",
    "Tezos takes the mnemonic and hashes it with an optional passphrase to formulate a secret key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'produce crew giant travel valid chaos assault myself buffalo such window relief mercy famous arctic color quantum echo course bunker guitar tortoise farm copy'\n",
      "b313d7649ff4468c7291fa8bc289d55ea98f327b02a569538290ff2ffa1142049623a9f439ab7c87c747b7635bc4034806986339048ae2f1cf3a745198e93095\n",
      "b313d7649ff4468c7291fa8bc289d55ea98f327b02a569538290ff2ffa114204\n"
     ]
    }
   ],
   "source": [
    "password = ''\n",
    "mnemonic = my_phrase\n",
    "passphrase = 'mnemonic' + password\n",
    "mnemonic_bytes = mnemonic.encode(\"utf-8\")\n",
    "print(mnemonic_bytes)\n",
    "passphrase_bytes = passphrase.encode(\"utf-8\")\n",
    "stretched = hl.pbkdf2_hmac(\"sha512\", mnemonic_bytes, passphrase_bytes, 2048)\n",
    "seed = stretched[:64]\n",
    "print(seed.hex())\n",
    "# for P256/secp256r1 secret exponent is the first 32 bytes of the seed\n",
    "secret_exponent = seed[:32]\n",
    "print(secret_exponent.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: 0x34e4e30d7824347ba7ea79c8ebf2d71531ac0ff200e2732b8535e20bc8c6cabe\n",
      "Y: 0x99b7582413d274775f704fa826fdbe4e9544388f80ee205f0d5de0d2d1b522dd\n",
      "(On curve <P256>)\n",
      "0334e4e30d7824347ba7ea79c8ebf2d71531ac0ff200e2732b8535e20bc8c6cabe\n"
     ]
    }
   ],
   "source": [
    "# P256\n",
    "import fastecdsa.keys \n",
    "import fastecdsa.curve\n",
    "from fastecdsa.encoding.util import bytes_to_int\n",
    "import fastecdsa.encoding.sec1\n",
    "from pyblake2 import blake2b\n",
    "from pytezos.crypto.encoding import base58_decode, base58_encode\n",
    "\n",
    "pk = fastecdsa.keys.get_public_key(bytes_to_int(secret_exponent), curve=fastecdsa.curve.P256)\n",
    "public_point = fastecdsa.encoding.sec1.SEC1Encoder.encode_public_key(pk)\n",
    "print(pk)\n",
    "print(public_point.hex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "394dd12312883880e4ade8d631be039d99f4020b\n",
      "tz3RZ3MQsNNHCbPtohBZh4wGAMJH9BgTKV1m\n"
     ]
    }
   ],
   "source": [
    "pkh = blake2b(data=public_point, digest_size=20).digest()\n",
    "print(pkh.hex())\n",
    "prefix = b'tz3'\n",
    "public_hash = base58_encode(pkh, prefix).decode()\n",
    "print(public_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pytezos.crypto.key.Key object at 0x7fefd6e33fa0>\n",
       "\n",
       "Public key hash\n",
       "tz3RZ3MQsNNHCbPtohBZh4wGAMJH9BgTKV1m\n",
       "\n",
       "Helpers\n",
       ".blinded_public_key_hash()\n",
       ".from_alias()\n",
       ".from_encoded_key()\n",
       ".from_faucet()\n",
       ".from_mnemonic()\n",
       ".from_public_point()\n",
       ".from_secret_exponent()\n",
       ".generate()\n",
       ".public_key()\n",
       ".public_key_hash()\n",
       ".secret_key()\n",
       ".sign()\n",
       ".verify()"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare to pytezos results\n",
    "from pytezos.crypto.key import Key\n",
    "p2pk = Key.from_public_point(\n",
    "    bytes.fromhex(public_point.hex()), \n",
    "    curve=b'p2')\n",
    "p2pk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "\n",
    "How does a ledger convert seed phrase into keys and key hash? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
